{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.讀入tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.讀入數據集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train,y_train),(x_test,y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   0,   0,  18,\n",
       "        107, 119, 103,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  99, 155,\n",
       "        113,  61, 118, 173, 117,   0,   0,   3,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   1,   0, 110, 136,   0,\n",
       "          0,   0,   0,   0, 167, 159,   0,   0,   2,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   1,   0,   6,   0,  72, 147,   0,   0,\n",
       "          5,   0,   2,   0,   0, 174, 118,   0,   5,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   1,   5,   0,   0, 174,   4,   0,   4,\n",
       "          0,   0,   0,   0,   0,   0, 204,  44,   0,   4,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   8,   0, 125, 128,   0,   9,   0,\n",
       "          0,   0,   0,   0,   2,   0, 107, 152,   0,   6,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0, 184,   9,   0,   4,   0,\n",
       "          0,   0,   0,   0,   2,   0,   0, 190,   0,   0,   2,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   1,   0,   2,   0,  73, 158,   0,   0,   0,   0,\n",
       "          1,   0,   0,   0,   0,   4,   0, 157,  79,   0,   3,   1,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   2,   5,   1,   0,   0, 157,  98,   0,   2,   0,   0,\n",
       "          1,   0,   0,   0,   0,   5,   0, 121, 145,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0, 231,  84,   0,   2,   1,   1,\n",
       "          0,   0,   0,   0,   0,   1,   0,  92, 223,  16,   0,   7,   4,\n",
       "          1,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  38, 183,  81,   0,   0,   0,   2,\n",
       "          2,   1,   2,   1,   0,   1,   0, 120, 226,  57,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0, 173, 216, 193, 213, 183, 164, 167,  98,  16,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0, 107, 141, 111,  91,  90, 108,\n",
       "         50,   0],\n",
       "       [  0,   0, 185, 221, 217, 210, 202, 222, 200, 206, 202, 204, 109,\n",
       "         27,  12,  17,  61, 136, 180, 221, 202, 225, 208, 214, 223, 240,\n",
       "        162,   0],\n",
       "       [  0,   0, 183, 220, 205, 200, 193, 184, 189, 182, 173, 194, 215,\n",
       "        216, 205, 207, 207, 195, 185, 194, 194, 203, 212, 183, 193, 211,\n",
       "        153,   0],\n",
       "       [  0,   0, 190, 233, 203, 206, 214, 216, 195, 183, 176, 159, 175,\n",
       "        189, 202, 195, 186, 186, 182, 186, 195, 209, 235, 203, 202, 215,\n",
       "        136,   0],\n",
       "       [  0,   0, 180, 228, 201, 202, 188, 183, 178, 192, 186, 181, 181,\n",
       "        177, 204, 217, 175, 179, 184, 176, 166, 169, 175, 185, 152, 203,\n",
       "        107,   0],\n",
       "       [  0,   0, 167, 235, 200, 207, 207, 209, 207, 203, 198, 189, 182,\n",
       "        178, 186, 189, 178, 192, 197, 195, 192, 185, 184, 205, 187, 255,\n",
       "         61,   0],\n",
       "       [  0,   0, 152, 250, 208, 214, 209, 202, 200, 202, 205, 204, 200,\n",
       "        192, 198, 204, 195, 205, 206, 198, 199, 203, 214, 207, 179, 249,\n",
       "         55,   0],\n",
       "       [  0,   0, 126, 255, 211, 215, 210, 206, 203, 203, 203, 206, 204,\n",
       "        199, 206, 207, 200, 206, 201, 199, 202, 208, 215, 195, 174, 211,\n",
       "         15,   0],\n",
       "       [  0,   0, 107, 255, 212, 211, 210, 211, 208, 206, 206, 207, 208,\n",
       "        208, 217, 214, 205, 206, 204, 208, 211, 211, 220, 197, 182, 225,\n",
       "          0,   0],\n",
       "       [  0,   0,  63, 232, 211, 216, 212, 214, 212, 212, 214, 212, 211,\n",
       "        212, 223, 219, 210, 214, 213, 212, 211, 209, 217, 208, 168, 190,\n",
       "          0,   0],\n",
       "       [  0,   0,  14, 255, 218, 221, 215, 218, 218, 217, 215, 213, 211,\n",
       "        215, 228, 220, 216, 222, 217, 217, 216, 218, 212, 213, 189, 143,\n",
       "          0,   0],\n",
       "       [  0,   0,   0, 230, 227, 214, 217, 218, 216, 217, 217, 214, 216,\n",
       "        222, 226, 218, 218, 220, 219, 218, 217, 218, 217, 215, 216, 113,\n",
       "          0,   0],\n",
       "       [  0,   0,   0, 177, 233, 216, 223, 222, 213, 213, 215, 212, 220,\n",
       "        226, 221, 220, 221, 218, 222, 220, 220, 221, 217, 212, 219,  52,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,  10, 223, 222, 220, 211, 213, 215, 220, 222, 226,\n",
       "        226, 221, 223, 222, 222, 221, 218, 220, 219, 220, 223, 174,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0, 126, 241, 208, 210, 214, 214, 216, 216, 220,\n",
       "        220, 214, 213, 212, 212, 210, 215, 217, 218, 215, 236,  42,   0,\n",
       "          1,   0],\n",
       "       [  0,   0,   0,   0,   0, 188, 237, 230, 233, 255, 255, 255, 255,\n",
       "        255, 255, 255, 255, 255, 255, 255, 231, 229, 239, 161,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  63,  95, 108, 105, 100, 103, 104,\n",
       "        105, 102, 100,  98,  97,  96,  90,  80,  83,  60,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1a0553a1d68>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#顯示圖片\n",
    "plt.imshow(x_train[8787],cmap='Greys')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.資料整理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.01176471, 0.        ,\n",
       "       0.        , 0.22352941, 0.30588235, 0.34117647, 0.18431373,\n",
       "       0.09803922, 0.01568627, 0.        , 0.        , 0.        ,\n",
       "       0.00392157, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.01176471, 0.        , 0.04705882, 0.60392157, 0.48235294,\n",
       "       0.12941176, 0.22352941, 0.18823529, 0.32156863, 0.4627451 ,\n",
       "       0.21960784, 0.        , 0.        , 0.00392157, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.00784314, 0.        ,\n",
       "       0.36862745, 0.49019608, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.3372549 , 0.79607843, 0.15294118,\n",
       "       0.        , 0.01960784, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.00392157, 0.        , 0.00392157, 0.49019608, 0.32156863,\n",
       "       0.        , 0.00392157, 0.00392157, 0.01176471, 0.        ,\n",
       "       0.21568627, 0.52156863, 0.17647059, 0.        , 0.01568627,\n",
       "       0.00392157, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.00784314, 0.02352941,\n",
       "       0.00784314, 0.00784314, 0.00392157, 0.        , 0.        ,\n",
       "       0.07843137, 0.63921569, 0.29411765, 0.        , 0.00784314,\n",
       "       0.00784314, 0.00784314, 0.        , 0.42745098, 0.45490196,\n",
       "       0.27843137, 0.        , 0.00784314, 0.00392157, 0.00392157,\n",
       "       0.02352941, 0.01960784, 0.01568627, 0.        , 0.        ,\n",
       "       0.00784314, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.00392157, 0.71764706,\n",
       "       0.25490196, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.55294118, 0.49411765, 0.1254902 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.00392157, 0.        , 0.        ,\n",
       "       0.15686275, 0.25882353, 0.42352941, 0.46666667, 0.91764706,\n",
       "       0.98823529, 0.54117647, 0.28235294, 0.42352941, 0.16078431,\n",
       "       0.09019608, 0.11372549, 0.15686275, 0.10980392, 0.70196078,\n",
       "       0.18431373, 0.30980392, 0.49019608, 0.41960784, 0.39607843,\n",
       "       0.34901961, 0.36470588, 0.16862745, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.64705882, 0.91764706, 0.71372549,\n",
       "       0.82745098, 0.84313725, 0.81960784, 0.75294118, 0.67058824,\n",
       "       0.40784314, 0.70196078, 0.82745098, 0.79607843, 0.77647059,\n",
       "       0.77647059, 0.80784314, 0.74117647, 0.39215686, 0.55686275,\n",
       "       0.85098039, 0.69411765, 0.69411765, 0.70980392, 0.7254902 ,\n",
       "       0.70588235, 0.71764706, 0.21568627, 0.        , 0.04705882,\n",
       "       0.74901961, 0.68627451, 0.69803922, 0.78431373, 0.76470588,\n",
       "       0.75294118, 0.64705882, 0.71372549, 0.8       , 0.7254902 ,\n",
       "       0.65490196, 0.67843137, 0.68627451, 0.64313725, 0.67843137,\n",
       "       0.68627451, 0.77647059, 0.74117647, 0.64313725, 0.6627451 ,\n",
       "       0.65882353, 0.64313725, 0.62745098, 0.6       , 0.86666667,\n",
       "       0.50980392, 0.        , 0.03137255, 0.14509804, 0.67058824,\n",
       "       0.75686275, 0.80392157, 0.78431373, 0.63529412, 0.6627451 ,\n",
       "       0.63529412, 0.61176471, 0.64313725, 0.67058824, 0.6627451 ,\n",
       "       0.67843137, 0.65882353, 0.63529412, 0.67058824, 0.67058824,\n",
       "       0.69803922, 0.70980392, 0.67058824, 0.6627451 , 0.6627451 ,\n",
       "       0.6745098 , 0.78823529, 0.6627451 , 0.17647059, 0.        ,\n",
       "       0.10196078, 0.46666667, 0.79215686, 0.81568627, 0.84313725,\n",
       "       0.7372549 , 0.58823529, 0.6627451 , 0.68235294, 0.67058824,\n",
       "       0.63921569, 0.67058824, 0.69411765, 0.70980392, 0.6627451 ,\n",
       "       0.64705882, 0.68627451, 0.6745098 , 0.69411765, 0.70588235,\n",
       "       0.69803922, 0.70588235, 0.72156863, 0.69411765, 0.69411765,\n",
       "       0.30588235, 0.17254902, 0.        , 0.06666667, 0.78431373,\n",
       "       0.75686275, 0.81568627, 0.85490196, 0.78431373, 0.72156863,\n",
       "       0.70588235, 0.68235294, 0.71372549, 0.70588235, 0.71372549,\n",
       "       0.70588235, 0.70980392, 0.69411765, 0.67843137, 0.69803922,\n",
       "       0.70588235, 0.6745098 , 0.67843137, 0.70588235, 0.72156863,\n",
       "       0.73333333, 0.74117647, 0.74509804, 0.81176471, 0.0745098 ,\n",
       "       0.        , 0.24705882, 0.66666667, 0.74117647, 0.81960784,\n",
       "       0.83529412, 0.69019608, 0.7254902 , 0.73333333, 0.69411765,\n",
       "       0.69019608, 0.71372549, 0.7254902 , 0.71764706, 0.72156863,\n",
       "       0.76078431, 0.76078431, 0.7372549 , 0.74117647, 0.7254902 ,\n",
       "       0.71764706, 0.72941176, 0.70980392, 0.69019608, 0.68235294,\n",
       "       0.70196078, 0.76862745, 0.04313725, 0.3372549 , 0.70980392,\n",
       "       0.71764706, 0.80392157, 0.83529412, 0.81568627, 0.65882353,\n",
       "       0.70588235, 0.7254902 , 0.7254902 , 0.72941176, 0.71764706,\n",
       "       0.72156863, 0.70196078, 0.71764706, 0.72941176, 0.71372549,\n",
       "       0.71372549, 0.73333333, 0.7372549 , 0.72156863, 0.70980392,\n",
       "       0.72156863, 0.7254902 , 0.73333333, 0.73333333, 0.81176471,\n",
       "       0.01960784, 0.4       , 1.        , 0.85882353, 0.85098039,\n",
       "       0.91764706, 0.76078431, 0.71372549, 0.73333333, 0.72941176,\n",
       "       0.7254902 , 0.73333333, 0.7254902 , 0.72941176, 0.71764706,\n",
       "       0.7254902 , 0.71764706, 0.70980392, 0.71764706, 0.72156863,\n",
       "       0.7372549 , 0.73333333, 0.73333333, 0.72941176, 0.73333333,\n",
       "       0.72156863, 0.7372549 , 0.78431373, 0.        , 0.11764706,\n",
       "       0.83921569, 0.87843137, 0.90196078, 0.85490196, 0.70980392,\n",
       "       0.75294118, 0.75686275, 0.75686275, 0.76470588, 0.77647059,\n",
       "       0.76470588, 0.76470588, 0.76078431, 0.75686275, 0.74117647,\n",
       "       0.74117647, 0.74117647, 0.7254902 , 0.74509804, 0.74117647,\n",
       "       0.74117647, 0.75686275, 0.77647059, 0.74901961, 0.75686275,\n",
       "       0.77647059, 0.        , 0.        , 0.        , 0.44705882,\n",
       "       0.85490196, 0.70980392, 0.73333333, 0.76470588, 0.71372549,\n",
       "       0.72156863, 0.74117647, 0.74509804, 0.73333333, 0.73333333,\n",
       "       0.74117647, 0.75686275, 0.76078431, 0.74509804, 0.75294118,\n",
       "       0.77647059, 0.77647059, 0.75686275, 0.75294118, 0.76470588,\n",
       "       0.76470588, 0.75686275, 0.76862745, 0.74901961, 0.        ,\n",
       "       0.        , 0.        , 0.2627451 , 0.89803922, 0.71764706,\n",
       "       0.74509804, 0.70196078, 0.70980392, 0.74901961, 0.74117647,\n",
       "       0.74901961, 0.74509804, 0.74509804, 0.72941176, 0.7372549 ,\n",
       "       0.74509804, 0.74509804, 0.74509804, 0.75294118, 0.76470588,\n",
       "       0.77254902, 0.76862745, 0.74509804, 0.74901961, 0.76470588,\n",
       "       0.75294118, 0.6745098 , 0.        , 0.00392157, 0.        ,\n",
       "       0.16862745, 0.8       , 0.74901961, 0.75294118, 0.73333333,\n",
       "       0.7254902 , 0.73333333, 0.74509804, 0.75294118, 0.74901961,\n",
       "       0.73333333, 0.7254902 , 0.74509804, 0.77254902, 0.78431373,\n",
       "       0.77254902, 0.76078431, 0.78039216, 0.8       , 0.78431373,\n",
       "       0.78431373, 0.78823529, 0.70980392, 0.75294118, 0.67843137,\n",
       "       0.        , 0.00392157, 0.        , 0.        , 0.68627451,\n",
       "       0.74117647, 0.72941176, 0.71372549, 0.69411765, 0.68627451,\n",
       "       0.70196078, 0.7254902 , 0.72941176, 0.70980392, 0.71372549,\n",
       "       0.7254902 , 0.7254902 , 0.72156863, 0.71372549, 0.71764706,\n",
       "       0.72941176, 0.76078431, 0.75686275, 0.80392157, 0.56078431,\n",
       "       0.10980392, 0.65882353, 0.65098039, 0.        , 0.00784314,\n",
       "       0.        , 0.        , 0.96862745, 0.81176471, 0.77647059,\n",
       "       0.87843137, 0.89019608, 0.89019608, 0.89411765, 0.91764706,\n",
       "       0.93333333, 0.94117647, 0.94901961, 0.92941176, 0.90980392,\n",
       "       0.91764706, 0.92941176, 0.9254902 , 0.9254902 , 0.93333333,\n",
       "       0.91372549, 0.99607843, 0.75294118, 0.4       , 0.78823529,\n",
       "       0.68627451, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.22745098, 0.34901961, 0.35686275, 0.38431373, 0.38431373,\n",
       "       0.34509804, 0.30588235, 0.30196078, 0.30588235, 0.32156863,\n",
       "       0.30588235, 0.28627451, 0.2627451 , 0.25098039, 0.25490196,\n",
       "       0.25490196, 0.24313725, 0.23529412, 0.22352941, 0.20392157,\n",
       "       0.18431373, 0.24313725, 0.3254902 , 0.09019608, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        ])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = x_train.reshape(60000,784)/255\n",
    "x_test = x_test.reshape(10000,784)/255\n",
    "x_train[99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = to_categorical(y_test,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[188]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#打造神經網絡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.333)  \n",
    "sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#開一台學習機\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0328 13:33:01.756811  3304 deprecation.py:506] From E:\\anaconda\\anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "#神經網絡\n",
    "model.add(Dense(99,input_dim=784,activation='relu'))\n",
    "model.add(Dense(99,activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#輸出層\n",
    "model.add(Dense(10,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#組裝神經網絡\n",
    "model.compile(loss='mse',optimizer=SGD(lr=0.087),metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 99)                77715     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 99)                9900      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1000      \n",
      "=================================================================\n",
      "Total params: 88,615\n",
      "Trainable params: 88,615\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77715"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "784*99+99"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.訓練資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "60000/60000 [==============================] - 4s 60us/sample - loss: 0.0187 - acc: 0.8751\n",
      "Epoch 2/25\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: 0.0185 - acc: 0.8758\n",
      "Epoch 3/25\n",
      "60000/60000 [==============================] - 4s 60us/sample - loss: 0.0184 - acc: 0.8770\n",
      "Epoch 4/25\n",
      "60000/60000 [==============================] - 4s 59us/sample - loss: 0.0182 - acc: 0.8786\n",
      "Epoch 5/25\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: 0.0180 - acc: 0.8799\n",
      "Epoch 6/25\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: 0.0179 - acc: 0.8806\n",
      "Epoch 7/25\n",
      "60000/60000 [==============================] - 3s 55us/sample - loss: 0.0178 - acc: 0.8814\n",
      "Epoch 8/25\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: 0.0176 - acc: 0.8824\n",
      "Epoch 9/25\n",
      "60000/60000 [==============================] - 4s 67us/sample - loss: 0.0175 - acc: 0.8826\n",
      "Epoch 10/25\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 0.0174 - acc: 0.8832\n",
      "Epoch 11/25\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: 0.0173 - acc: 0.8849\n",
      "Epoch 12/25\n",
      "60000/60000 [==============================] - 4s 59us/sample - loss: 0.0171 - acc: 0.8855\n",
      "Epoch 13/25\n",
      "60000/60000 [==============================] - 3s 58us/sample - loss: 0.0170 - acc: 0.8860\n",
      "Epoch 14/25\n",
      "60000/60000 [==============================] - 3s 58us/sample - loss: 0.0169 - acc: 0.8873\n",
      "Epoch 15/25\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: 0.0168 - acc: 0.8882\n",
      "Epoch 16/25\n",
      "60000/60000 [==============================] - 4s 59us/sample - loss: 0.0167 - acc: 0.8883\n",
      "Epoch 17/25\n",
      "60000/60000 [==============================] - 3s 58us/sample - loss: 0.0166 - acc: 0.8894\n",
      "Epoch 18/25\n",
      "60000/60000 [==============================] - 4s 59us/sample - loss: 0.0165 - acc: 0.8900\n",
      "Epoch 19/25\n",
      "60000/60000 [==============================] - 3s 58us/sample - loss: 0.0164 - acc: 0.8905\n",
      "Epoch 20/25\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: 0.0163 - acc: 0.8917\n",
      "Epoch 21/25\n",
      "60000/60000 [==============================] - 4s 59us/sample - loss: 0.0162 - acc: 0.8918\n",
      "Epoch 22/25\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 0.0162 - acc: 0.8928\n",
      "Epoch 23/25\n",
      "60000/60000 [==============================] - 4s 70us/sample - loss: 0.0160 - acc: 0.8937\n",
      "Epoch 24/25\n",
      "60000/60000 [==============================] - 4s 61us/sample - loss: 0.0159 - acc: 0.8944\n",
      "Epoch 25/25\n",
      "60000/60000 [==============================] - 3s 58us/sample - loss: 0.0159 - acc: 0.8936\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a0553ca828>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,batch_size=50,epochs=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.訓練成果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.predict_classes(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(result[1])\n",
    "print(y_test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
